{
    "config_class": "DQNAuxAgentConfig",
    "fixed_parameters": {
        "exp_name": "result/picky_eater/linear_vf/representation/dqn_aux/control_info/sweep_3f_xy",
        "env_name": "CollectTwoColorRGB",
        "agent": "DQNAuxSuccessorAgent",
        "discount": 0.99,
        "state_norm_coef": 255.0,

        "decay_epsilon": true,
        "epsilon_start": 1.0,
        "epsilon_end": 0.1,
        "epsilon_schedule_steps": 100000,

        "rep_config": {
            "rep_type": "online",
            "network_type": "conv",
            "conv_architecture": {
                "conv_layers": [
                   {"in": 3,  "out": 32, "kernel": 4, "stride": 1, "pad": 1},
                   {"in": 32,  "out": 16, "kernel": 4, "stride": 2, "pad": 2}
                ]
            },
            "in_dim": [15, 15, 3],
            "out_dim": 64,
            "load_params": false,
            "train_rep": true
        },

        "val_fn_config": { 
"val_fn_type": "linear",
"init_type": "xavier"
        },

        "replay": true,
        "memory_size": 100000,
        "batch_size": 32,

        "optimizer_type": "Adam",
        "use_target_network": true,
        "target_network_update_freq": 1024,
        
        "max_steps": 1000000,
        "log_interval": 10000,
        "eval_interval": 10000,
        "eval_episodes": 100,
        "save_interval": 0,
        "timeout": 500,
        "stats_queue_size": 100,
 	"save_early": {"mean": 2.95, "min": 1.5},

	"distance_paths": [{"current": "example/picky_eater/trained_dqn/3f/distance_current_states_sameEP_green.npy", "action": "example/picky_eater/trained_dqn/3f/distance_actions_sameEP_green.npy", "next": "example/picky_eater/trained_dqn/3f/distance_next_states_sameEP_green.npy", "reward": "example/picky_eater/trained_dqn/3f/distance_rewards_sameEP_green.npy", "terminal": "example/picky_eater/trained_dqn/3f/distance_terminals_sameEP_green.npy", "label": "Green"}, {"current": "example/picky_eater/trained_dqn/3f/distance_current_states_sameEP_red.npy", "action": "example/picky_eater/trained_dqn/3f/distance_actions_sameEP_red.npy", "next": "example/picky_eater/trained_dqn/3f/distance_next_states_sameEP_red.npy", "reward": "example/picky_eater/trained_dqn/3f/distance_rewards_sameEP_red.npy", "terminal": "example/picky_eater/trained_dqn/3f/distance_terminals_sameEP_red.npy", "label": "Red"}, {"current": "example/picky_eater/trained_dqn/3f/distance_current_states_sameEP_random.npy", "action": "example/picky_eater/trained_dqn/3f/distance_actions_sameEP_random.npy", "next": "example/picky_eater/trained_dqn/3f/distance_next_states_sameEP_random.npy", "reward": "example/picky_eater/trained_dqn/3f/distance_rewards_sameEP_random.npy", "terminal": "example/picky_eater/trained_dqn/3f/distance_terminals_sameEP_random.npy", "label": "Random"}],

    	"online_property": false,
        "tensorboard_logs": false,
        "save_params": true,
        "visualize": false,
        "evaluate_lipschitz": false,
        "evaluate_distance": false,
        "evaluate_orthogonality": false,
    	"evaluate_interference": false,
    	"evaluate_diversity": false,
        "evaluate_sparsity": false,
        "evaluate_regression": false,
	"fruit_num": 3,
        "rewarding_color": "green",
        "single_channel_color": true
    },
   "sweep_parameters": {
        "learning_rate": [0.001, 0.0003, 0.0001, 0.00003, 0.00001],
        "aux_config": [
            [
                {
                "aux_fn_type":  "linear",
                "aux_out_dim": 4,
                "aux_task": "aux_control_collect",
                "discount": 0.9,
                "flip_reward":  true,
                "aux_weight": 1
                },
                {
                "aux_fn_type":  "linear",
                "aux_in_dim": 64,
                "aux_out_dim": 2,
                "aux_task": "rgb2xy",
                "aux_weight": 0.0001
                }           
	    ]
        ]
   }
}
