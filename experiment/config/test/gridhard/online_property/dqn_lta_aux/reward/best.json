{
    "config_class": "DQNAuxAgentConfig",
    "fixed_parameters": {
        "exp_name": "test/gridhard/online_property/dqn_lta_aux/reward/best",
        "env_name": "GridHardRGB",
        "agent": "DQNAuxAgent",
        "discount": 0.99,
        "state_norm_coef": 255.0,

        "epsilon": 0.1,

        "rep_config": {
            "rep_type": "modular",
            "network_type": "conv",
            "conv_architecture": {
                "conv_layers": [
                   {"in": 3,  "out": 16, "kernel": 4, "stride": 2, "pad": 2},
                   {"in": 16,  "out": 16, "kernel": 4, "stride": 2, "pad": 2},
                   {"in": 16,  "out": 8, "kernel": 4, "stride": 2, "pad": 2}
                ]
            },
            "in_dim": [15, 15, 3],
            "out_dim": 32,
            "load_params": false,
            "train_rep": true
        },

        "activation_config": {
            "name": "LTA",
            "input": 32,
            "tile": 20,
            "eta": 0.4,
            "bound_high": 2,
            "bound_low": -2
        },

        "val_fn_config": {
            "val_fn_type": "linear",
	        "init_type": "lta"
         },

        "aux_config": [
            {
            "aux_fn_type":  "linear",
            "aux_in_dim": 640,
            "aux_out_dim": 1,
            "aux_task": "reward_predictor"
            }
        ],

        "replay": true,
        "memory_size": 10000,
        "batch_size": 32,

        "optimizer_type": "Adam",
        "use_target_network": true,
        "target_network_update_freq": 64,

        "max_steps": 300000,
        "log_interval": 10000,
        "eval_interval": 10000,
        "eval_episodes": 5,
        "save_interval": 0,
        "timeout": 100,
        "stats_queue_size": 100,

        "save_params": true,
        "tensorboard_logs": true,
        "visualize": false,

        "online_property": true,
        "evaluate_lipschitz": true,
        "evaluate_distance": true,
        "evaluate_orthogonality": true,
        "evaluate_noninterference": true,
        "evaluate_decorrelation": true,
        "distance_path": {"current": "test/gridhard/random_dqn/distance_current_states.npy", "action": "test/gridhard/random_dqn/distance_actions.npy", "next": "test/gridhard/random_dqn/distance_next_states.npy", "reward": "test/gridhard/random_dqn/distance_rewards.npy", "terminal": "test/gridhard/random_dqn/distance_terminals.npy"}
    },
    "sweep_parameters": {
        "learning_rate": [0.0003]
    }
}
