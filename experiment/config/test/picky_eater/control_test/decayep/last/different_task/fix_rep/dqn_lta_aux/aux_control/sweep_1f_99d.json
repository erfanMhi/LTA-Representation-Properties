{
    "config_class": "DQNAgentConfig",
    "fixed_parameters": {
	"exp_name": "test/picky_eater/control_test/decayep/last/different_task/fix_rep/dqn_lta_aux/aux_control/sweep_1f_99d",
        "env_name": "CollectTwoColorLip",
        "agent": "DQNAgent",
        "discount": 0.99,
        "state_norm_coef": 255.0,

        "decay_epsilon": true,
        "epsilon_start": 1.0,
        "epsilon_end": 0.1,
        "epsilon_schedule_steps": 100000,
 
        "rep_config": {
            "rep_type": "online",
            "network_type": "conv",
            "conv_architecture": {
                "conv_layers": [
                   {"in": 3,  "out": 32, "kernel": 4, "stride": 1, "pad": 1},
                   {"in": 32,  "out": 32, "kernel": 4, "stride": 1, "pad": 1},
                   {"in": 32,  "out": 64, "kernel": 4, "stride": 2, "pad": 2}
                ],
                "fc_layers": {"hidden_units":[128, 128]}
            },
            "in_dim": [15, 15, 3],
            "out_dim": 32,
            "load_params": true,
            "train_rep": false,
            "path": "test/picky_eater/representation/dqn_lta_aux/aux_control/best_1f_99d/{}_run/0_param_setting/parameters/rep_net"
        },

        "val_fn_config": {
            "val_fn_type": "linear",
	        "init_type": "lta"
         },
        
	 "activation_config": {
            "name": "LTA",
            "input": 32,
            "tile": 20,
            "eta": 1.0,
            "bound_high": 10,
            "bound_low": -10
        },


        "replay": true,
        "memory_size": 10000,
        "batch_size": 32,

        "optimizer_type": "Adam",
        "use_target_network": true,
        "target_network_update_freq": 2048,

        "max_steps": 1000000,
        "log_interval": 10000,
        "eval_interval": 10000,
        "eval_episodes": 5,
        "save_interval": 0,
        "timeout": 500,
        "stats_queue_size": 100,

        "tensorboard_logs": false,
        "save_params": false,
        "visualize": false,
        "visualize_aux_distance": false,
        "rewarding_color": "red",
	"fruit_num": 1,
        "evaluate_lipschitz": true,
        "lipschitz_sampled_states_path": "example/picky_eater/trained_dqn/lip_sampled_states.npy"
    },
    "sweep_parameters": {
        "learning_rate": [0.001, 0.0003, 0.0001, 0.00003, 0.00001, 0.000003, 0.000001, 0.0000003],
        "memory_size": [100000],
        "epsilon_end": [0.1],
        "target_network_update_freq": [1024]
    }
}
